diff --git a/client/src/api/schema/schema.ts b/client/src/api/schema/schema.ts
index 254039919c94..a6f4653ab839 100644
--- a/client/src/api/schema/schema.ts
+++ b/client/src/api/schema/schema.ts
@@ -615,6 +615,23 @@ export interface paths {
         patch?: never;
         trace?: never;
     };
+    "/api/datasets/{dataset_id}/report": {
+        parameters: {
+            query?: never;
+            header?: never;
+            path?: never;
+            cookie?: never;
+        };
+        /** Return JSON content Galaxy will use to render Markdown reports */
+        get: operations["report_api_datasets__dataset_id__report_get"];
+        put?: never;
+        post?: never;
+        delete?: never;
+        options?: never;
+        head?: never;
+        patch?: never;
+        trace?: never;
+    };
     "/api/datasets/{dataset_id}/storage": {
         parameters: {
             query?: never;
@@ -17047,6 +17064,27 @@ export interface components {
              */
             values: string;
         };
+        /** ToolReportForDataset */
+        ToolReportForDataset: {
+            /**
+             * Content
+             * @description Raw text contents of the last page revision (type dependent on content_format).
+             * @default
+             */
+            content: string | null;
+            /**
+             * Galaxy Version
+             * @description The version of Galaxy this object was generated with.
+             */
+            generate_time?: string | null;
+            /**
+             * Galaxy Version
+             * @description The version of Galaxy this object was generated with.
+             */
+            generate_version?: string | null;
+        } & {
+            [key: string]: unknown;
+        };
         /** ToolStep */
         ToolStep: {
             /**
@@ -20320,7 +20358,10 @@ export interface operations {
     };
     get_content_as_text_api_datasets__dataset_id__get_content_as_text_get: {
         parameters: {
-            query?: never;
+            query?: {
+                /** @description If non-null, get the specified filename from the extra files for this dataset. */
+                filename?: string | null;
+            };
             header?: {
                 /** @description The user ID that will be used to effectively make this API call. Only admins and designated users can make API calls on behalf of other users. */
                 "run-as"?: string | null;
@@ -20653,6 +20694,50 @@ export interface operations {
             };
         };
     };
+    report_api_datasets__dataset_id__report_get: {
+        parameters: {
+            query?: never;
+            header?: {
+                /** @description The user ID that will be used to effectively make this API call. Only admins and designated users can make API calls on behalf of other users. */
+                "run-as"?: string | null;
+            };
+            path: {
+                /** @description The ID of the History Dataset. */
+                dataset_id: string;
+            };
+            cookie?: never;
+        };
+        requestBody?: never;
+        responses: {
+            /** @description Successful Response */
+            200: {
+                headers: {
+                    [name: string]: unknown;
+                };
+                content: {
+                    "application/json": components["schemas"]["ToolReportForDataset"];
+                };
+            };
+            /** @description Request Error */
+            "4XX": {
+                headers: {
+                    [name: string]: unknown;
+                };
+                content: {
+                    "application/json": components["schemas"]["MessageExceptionModel"];
+                };
+            };
+            /** @description Server Error */
+            "5XX": {
+                headers: {
+                    [name: string]: unknown;
+                };
+                content: {
+                    "application/json": components["schemas"]["MessageExceptionModel"];
+                };
+            };
+        };
+    };
     show_storage_api_datasets__dataset_id__storage_get: {
         parameters: {
             query?: {
diff --git a/client/src/components/Dataset/DatasetAsImage/DatasetAsImage.vue b/client/src/components/Dataset/DatasetAsImage/DatasetAsImage.vue
index 492f48210c40..4271ad3786ad 100644
--- a/client/src/components/Dataset/DatasetAsImage/DatasetAsImage.vue
+++ b/client/src/components/Dataset/DatasetAsImage/DatasetAsImage.vue
@@ -15,9 +15,9 @@ const { datasetPathDestination } = useDatasetPathDestination();
 
 const props = defineProps<Props>();
 
-const pathDestination = computed<PathDestination | null>(() =>
-    datasetPathDestination.value(props.historyDatasetId, props.path)
-);
+const pathDestination = computedAsync<PathDestination | null>(async () => {
+    return await datasetPathDestination.value(props.historyDatasetId, props.path);
+}, null);
 
 const imageUrl = computed(() => {
     if (props.path === undefined || props.path === "undefined") {
diff --git a/client/src/components/Dataset/DatasetIndex/DatasetIndex.vue b/client/src/components/Dataset/DatasetIndex/DatasetIndex.vue
index 5001d7f2b20a..a0e2ac3514d2 100644
--- a/client/src/components/Dataset/DatasetIndex/DatasetIndex.vue
+++ b/client/src/components/Dataset/DatasetIndex/DatasetIndex.vue
@@ -1,4 +1,5 @@
 <script setup lang="ts">
+import { computedAsync } from "@vueuse/core";
 import { computed } from "vue";
 
 import type { DatasetExtraFiles } from "@/api/datasets";
@@ -13,7 +14,7 @@ const { datasetPathDestination } = useDatasetPathDestination();
 
 const props = defineProps<Props>();
 
-const pathDestination = computed<PathDestination | null>(() =>
+const pathDestination = computedAsync<PathDestination | null>(() =>
     datasetPathDestination.value(props.historyDatasetId, props.path)
 );
 
diff --git a/client/src/components/Dataset/DatasetLink/DatasetLink.vue b/client/src/components/Dataset/DatasetLink/DatasetLink.vue
index 1e9bbc33423d..ff73b85068e0 100644
--- a/client/src/components/Dataset/DatasetLink/DatasetLink.vue
+++ b/client/src/components/Dataset/DatasetLink/DatasetLink.vue
@@ -1,4 +1,5 @@
 <script setup lang="ts">
+import { computedAsync } from "@vueuse/core";
 import { computed } from "vue";
 
 import { hasDetails } from "@/api";
@@ -16,7 +17,7 @@ const { getDataset } = useDatasetStore();
 
 const props = defineProps<Props>();
 
-const pathDestination = computed<PathDestination | null>(() =>
+const pathDestination = computedAsync<PathDestination | null>(() =>
     datasetPathDestination.value(props.historyDatasetId, props.path)
 );
 
diff --git a/client/src/components/History/Content/ContentItem.vue b/client/src/components/History/Content/ContentItem.vue
index 70279f033290..4f5e58dcd06a 100644
--- a/client/src/components/History/Content/ContentItem.vue
+++ b/client/src/components/History/Content/ContentItem.vue
@@ -171,8 +171,12 @@ const itemUrls = computed<ItemUrls>(() => {
                     : null,
         };
     }
+    let display = `/datasets/${id}/preview`;
+    if (props.item.extension == "tool_markdown") {
+        display = `/datasets/${id}/report`;
+    }
     return {
-        display: `/datasets/${id}/preview`,
+        display: display,
         edit: `/datasets/${id}/edit`,
         showDetails: `/datasets/${id}/details`,
         reportError: `/datasets/${id}/error`,
diff --git a/client/src/components/Markdown/Markdown.vue b/client/src/components/Markdown/Markdown.vue
index d9856ec95e8b..042abef6fa28 100644
--- a/client/src/components/Markdown/Markdown.vue
+++ b/client/src/components/Markdown/Markdown.vue
@@ -30,6 +30,7 @@ const props = defineProps<{
     downloadEndpoint: string;
     readOnly?: boolean;
     exportLink?: string;
+    showIdentifier?: boolean;
 }>();
 
 // Refs and data
@@ -58,6 +59,10 @@ const updateTime = computed(() => {
     return "";
 });
 
+const pageTitle = computed(() => {
+    return props.markdownConfig.title || props.markdownConfig.model_class;
+});
+
 // Methods
 function initConfig() {
     const config = props.markdownConfig;
@@ -85,7 +90,7 @@ onMounted(() => {
             <div class="d-flex flex-column sticky-top bg-white">
                 <div class="d-flex">
                     <Heading v-localize h1 separator inline size="md" class="flex-grow-1">
-                        {{ markdownConfig.title || markdownConfig.model_class }}
+                        {{ pageTitle }}
                     </Heading>
                     <div>
                         <StsDownloadButton
diff --git a/client/src/components/Markdown/Sections/Elements/HistoryDatasetAsTable.vue b/client/src/components/Markdown/Sections/Elements/HistoryDatasetAsTable.vue
index fccbea90cfdf..a42292ffb1e0 100644
--- a/client/src/components/Markdown/Sections/Elements/HistoryDatasetAsTable.vue
+++ b/client/src/components/Markdown/Sections/Elements/HistoryDatasetAsTable.vue
@@ -11,6 +11,7 @@ interface HistoryDatasetAsTableProps {
     footer?: string;
     showColumnHeaders: boolean;
     title?: string;
+    path?: string;
 }
 
 const props = withDefaults(defineProps<HistoryDatasetAsTableProps>(), {
@@ -18,10 +19,15 @@ const props = withDefaults(defineProps<HistoryDatasetAsTableProps>(), {
     showColumnHeaders: true,
     title: undefined,
     footer: undefined,
+    path: undefined,
 });
 
 const itemUrl = computed(() => {
-    return `/api/datasets/${props.datasetId}/get_content_as_text`;
+    if (props.path) {
+        return `/api/datasets/${props.datasetId}/get_content_as_text?filename=${props.path}`;
+    } else {
+        return `/api/datasets/${props.datasetId}/get_content_as_text`;
+    }
 });
 
 const metaUrl = computed(() => {
diff --git a/client/src/components/Markdown/Sections/MarkdownGalaxy.vue b/client/src/components/Markdown/Sections/MarkdownGalaxy.vue
index 332a9dc8f41f..f2effea60e5c 100644
--- a/client/src/components/Markdown/Sections/MarkdownGalaxy.vue
+++ b/client/src/components/Markdown/Sections/MarkdownGalaxy.vue
@@ -160,7 +160,8 @@ watch(
                 :dataset-id="args.history_dataset_id"
                 :footer="args.footer"
                 :show-column-headers="argToBoolean(args, 'show_column_headers', true)"
-                :title="args.title" />
+                :title="args.title"
+                :path="path" />
             <HistoryDatasetCollectionDisplay
                 v-else-if="name == 'history_dataset_collection_display'"
                 :collection-id="args.history_dataset_collection_id" />
diff --git a/client/src/components/Tool/ToolReport.vue b/client/src/components/Tool/ToolReport.vue
new file mode 100644
index 000000000000..8fd17fff6f47
--- /dev/null
+++ b/client/src/components/Tool/ToolReport.vue
@@ -0,0 +1,39 @@
+<script setup lang="ts">
+import { computed, ref } from "vue";
+
+import { useConfig } from "@/composables/config";
+import { urlData } from "@/utils/url";
+
+import Markdown from "@/components/Markdown/Markdown.vue";
+
+interface Props {
+    datasetId: string;
+}
+
+const props = defineProps<Props>();
+
+const dataUrl = computed(() => {
+    return `/api/datasets/${props.datasetId}/report`;
+});
+
+const dataRef = ref<unknown>(null);
+
+const { config, isConfigLoaded } = useConfig(true);
+
+urlData({ url: dataUrl.value }).then((data) => {
+    dataRef.value = data;
+});
+</script>
+
+<template>
+    <div>
+        <Markdown
+            v-if="isConfigLoaded && dataRef"
+            :markdown-config="dataRef"
+            :enable-beta-markdown-export="config.enable_beta_markdown_export"
+            download-endpoint="TODO"
+            :show-identifier="false"
+            :read-only="true" />
+        <div v-else>Loading....</div>
+    </div>
+</template>
diff --git a/client/src/composables/datasetPathDestination.ts b/client/src/composables/datasetPathDestination.ts
index 89f419572d1a..39569e416e97 100644
--- a/client/src/composables/datasetPathDestination.ts
+++ b/client/src/composables/datasetPathDestination.ts
@@ -20,11 +20,11 @@ export function useDatasetPathDestination() {
     const cache = ref<{ [key: string]: PathDestinationMap }>({});
 
     const datasetPathDestination = computed(() => {
-        return (dataset_id: string, path?: string) => {
+        return async (dataset_id: string, path?: string) => {
             const targetPath = path ?? "undefined";
-            const pathDestination = cache.value[dataset_id]?.[targetPath];
+            let pathDestination = cache.value[dataset_id]?.[targetPath];
             if (!pathDestination) {
-                getPathDestination(dataset_id, path);
+                pathDestination = (await getPathDestination(dataset_id, path)) ?? undefined;
             }
             return pathDestination ?? null;
         };
@@ -36,7 +36,6 @@ export function useDatasetPathDestination() {
             await datasetExtraFilesStore.fetchDatasetExtFilesByDatasetId({ id: dataset_id });
             datasetExtraFiles = datasetExtraFilesStore.getDatasetExtraFiles(dataset_id);
         }
-
         if (datasetExtraFiles === null) {
             return null;
         }
@@ -66,9 +65,7 @@ export function useDatasetPathDestination() {
             }
             pathDestination.fileLink = getCompositeDatasetLink(dataset_id, datasetEntry.path);
         }
-
         set(cache.value, dataset_id, { [path]: pathDestination });
-
         return pathDestination;
     }
 
diff --git a/client/src/entry/analysis/router.js b/client/src/entry/analysis/router.js
index 0cc728093696..572bef96f8c1 100644
--- a/client/src/entry/analysis/router.js
+++ b/client/src/entry/analysis/router.js
@@ -23,6 +23,7 @@ import WorkflowLanding from "components/Landing/WorkflowLanding";
 import PageDisplay from "components/PageDisplay/PageDisplay";
 import PageForm from "components/PageDisplay/PageForm";
 import PageEditor from "components/PageEditor/PageEditor";
+import ToolReport from "components/Tool/ToolReport";
 import ToolSuccess from "components/Tool/ToolSuccess";
 import ToolsList from "components/ToolsList/ToolsList";
 import ToolsJson from "components/ToolsView/ToolsSchemaJson/ToolsJson";
@@ -236,6 +237,11 @@ export function getRouter(Galaxy) {
                             isPreview: true,
                         }),
                     },
+                    {
+                        path: "datasets/:datasetId/report",
+                        component: ToolReport,
+                        props: true,
+                    },
                     {
                         // legacy route, potentially used by 3rd parties
                         path: "datasets/:datasetId/show_params",
diff --git a/doc/parse_gx_xsd.py b/doc/parse_gx_xsd.py
index 11092bb84515..e143c649fd53 100644
--- a/doc/parse_gx_xsd.py
+++ b/doc/parse_gx_xsd.py
@@ -8,12 +8,16 @@
 from io import StringIO
 
 from lxml import etree
+from yaml import safe_load
 
 with open(sys.argv[2]) as f:
     xmlschema_doc = etree.parse(f)
 
 markdown_buffer = StringIO()
 
+DIRECTIVES_PATH = "../client/src/components/Markdown/directives.yml"
+DIRECTIVES = safe_load(open(DIRECTIVES_PATH))
+
 
 def main():
     """Entry point for the function that builds Markdown help for the Galaxy XSD."""
@@ -74,6 +78,7 @@ def _build_tag(tag, hide_attributes):
     annotation_el = tag_el.find("{http://www.w3.org/2001/XMLSchema}annotation")
     text = annotation_el.find("{http://www.w3.org/2001/XMLSchema}documentation").text
     text = _replace_attribute_list(tag, text, attributes)
+    text = _expand_directives(text)
     for line in text.splitlines():
         if line.startswith("$assertions"):
             assertions_tag = xmlschema_doc.find(
@@ -127,6 +132,29 @@ def _replace_attribute_list(tag, text, attributes):
     return text
 
 
+def _build_directive_table(line: str) -> str:
+    _, directives_str = line.split(":", 1)
+    directives = directives_str.split(",")
+    attribute_table = StringIO()
+    attribute_table.write("\n\n")
+    for directive in directives:
+        header_level = 3
+        header_prefix = "#" * header_level
+        attribute_table.write(f"\n{header_prefix} {directive}\n\n")
+        directive_info = DIRECTIVES[directive]
+        if "help" in directive_info:
+            attribute_table.write(DIRECTIVES[directive]["help"])
+    return attribute_table.getvalue()
+
+
+def _expand_directives(text):
+    for line in text.splitlines():
+        if not line.startswith("$directive_list:"):
+            continue
+        text = text.replace(line, _build_directive_table(line))
+    return text
+
+
 def _get_bp_link(annotation_el):
     anchor = annotation_el.attrib.get("{http://galaxyproject.org/xml/1.0}best_practices", None)
     link = None
diff --git a/lib/galaxy/config/sample/datatypes_conf.xml.sample b/lib/galaxy/config/sample/datatypes_conf.xml.sample
index c38dace35b44..8ad2491f8e5a 100644
--- a/lib/galaxy/config/sample/datatypes_conf.xml.sample
+++ b/lib/galaxy/config/sample/datatypes_conf.xml.sample
@@ -591,6 +591,7 @@
     <!-- End RGenetics Datatypes -->
     <datatype extension="ipynb" type="galaxy.datatypes.text:Ipynb" display_in_upload="true"/>
     <datatype extension="json" type="galaxy.datatypes.text:Json" display_in_upload="true"/>
+    <datatype extension="tool_markdown" type="galaxy.datatypes.text:Text"/>
     <datatype extension="expression.json" type="galaxy.datatypes.text:ExpressionJson" display_in_upload="true"/>
     <!-- graph datatypes -->
     <datatype extension="xgmml" type="galaxy.datatypes.graph:Xgmml" display_in_upload="true"/>
diff --git a/lib/galaxy/datatypes/data.py b/lib/galaxy/datatypes/data.py
index 6ee30e6ad7ec..0d73604c3ba8 100644
--- a/lib/galaxy/datatypes/data.py
+++ b/lib/galaxy/datatypes/data.py
@@ -465,6 +465,7 @@ def to_archive(self, dataset: DatasetProtocol, name: str = "") -> Iterable:
     def _serve_file_download(self, headers, data, trans, to_ext, file_size, **kwd):
         composite_extensions = trans.app.datatypes_registry.get_composite_extensions()
         composite_extensions.append("html")  # for archiving composite datatypes
+        composite_extensions.append("tool_markdown")  # basically should act as an HTML datatype in this capacity
         composite_extensions.append("data_manager_json")  # for downloading bundles if bundled.
         composite_extensions.append("directory")  # for downloading directories.
         composite_extensions.append("zarr")  # for downloading zarr directories.
diff --git a/lib/galaxy/managers/hdas.py b/lib/galaxy/managers/hdas.py
index abb31c1f0d9d..50014a350b48 100644
--- a/lib/galaxy/managers/hdas.py
+++ b/lib/galaxy/managers/hdas.py
@@ -286,9 +286,6 @@ def text_data(self, hda, preview=True):
         """
         Get data from text file, truncating if necessary.
         """
-        # 1 MB
-        MAX_PEEK_SIZE = 1000000
-
         truncated = False
         hda_data = None
         # For now, cannot get data from non-text datasets.
@@ -298,6 +295,11 @@ def text_data(self, hda, preview=True):
         if not os.path.exists(file_path):
             return truncated, hda_data
 
+        return self.text_data_truncated(file_path, preview=preview)
+
+    def text_data_truncated(self, file_path, preview=True):
+        # 1 MB
+        MAX_PEEK_SIZE = 1000000
         truncated = preview and os.stat(file_path).st_size > MAX_PEEK_SIZE
         with get_fileobj(file_path) as fh:
             try:
diff --git a/lib/galaxy/managers/markdown_util.py b/lib/galaxy/managers/markdown_util.py
index 179deae8fec4..75314767402f 100644
--- a/lib/galaxy/managers/markdown_util.py
+++ b/lib/galaxy/managers/markdown_util.py
@@ -1095,6 +1095,70 @@ def find_non_empty_group(match):
     return workflow_markdown
 
 
+def resolve_job_markdown(trans, job, job_markdown):
+    """Resolve job objects to convert tool markdown to 'internal' representation.
+
+    Replace references to abstract workflow parts with actual galaxy object IDs corresponding
+    to the actual executed workflow. For instance:
+
+        convert output=name -to- history_dataset_id=<id> | history_dataset_collection_id=<id>
+        convert input=name -to- history_dataset_id=<id> | history_dataset_collection_id=<id>
+        convert argument-less job directives to job
+    """
+    io_dicts = job.io_dicts()
+
+    def _remap(container, line):
+        if container == "history_link":
+            return (f"history_link(history_id={job.history.id})\n", False)
+        elif container == "tool_stdout":
+            return (f"tool_stdout(job_id={job.id})\n", False)
+        elif container == "tool_stderr":
+            return (f"tool_stderr(job_id={job.id})\n", False)
+        elif container == "job_parameters":
+            return (f"job_parameters(job_id={job.id})\n", False)
+        elif container == "job_metrics":
+            return (f"job_metrics(job_id={job.id})\n", False)
+        ref_object_type = None
+        output_match = re.search(OUTPUT_LABEL_PATTERN, line)
+        input_match = re.search(INPUT_LABEL_PATTERN, line)
+
+        def find_non_empty_group(match):
+            for group in match.groups():
+                if group:
+                    return group
+
+        target_match: Optional[Match]
+        ref_object: Optional[Any]
+        if output_match:
+            target_match = output_match
+            name = find_non_empty_group(target_match)
+            if name in io_dicts.out_data:
+                ref_object = io_dicts.out_data[name]
+            elif name in io_dicts.out_collections:
+                ref_object = io_dicts.out_collections[name]
+            else:
+                raise Exception("Unknown exception")
+        elif input_match:
+            target_match = input_match
+            name = find_non_empty_group(target_match)
+            ref_object = io_dicts.inp_data[name]
+        else:
+            target_match = None
+            ref_object = None
+        if ref_object:
+            assert target_match  # tell type system, this is set when ref_object is set
+            if ref_object_type is None:
+                if ref_object.history_content_type == "dataset":
+                    ref_object_type = "history_dataset"
+                else:
+                    ref_object_type = "history_dataset_collection"
+            line = line.replace(target_match.group(), f"{ref_object_type}_id={ref_object.id}")
+        return (line, False)
+
+    galaxy_markdown = _remap_galaxy_markdown_calls(_remap, job_markdown)
+    return galaxy_markdown
+
+
 def _remap_galaxy_markdown_containers(func, markdown):
     new_markdown = markdown
 
diff --git a/lib/galaxy/schema/schema.py b/lib/galaxy/schema/schema.py
index aedb8e2e43f2..fcf28ebe0617 100644
--- a/lib/galaxy/schema/schema.py
+++ b/lib/galaxy/schema/schema.py
@@ -3945,6 +3945,13 @@ class PageDetails(PageSummary):
     model_config = ConfigDict(extra="allow")
 
 
+class ToolReportForDataset(BaseModel):
+    content: Optional[str] = ContentField
+    generate_version: Optional[str] = GenerateVersionField
+    generate_time: Optional[str] = GenerateTimeField
+    model_config = ConfigDict(extra="allow")
+
+
 class PageSummaryList(RootModel):
     root: List[PageSummary] = Field(
         default=[],
diff --git a/lib/galaxy/tool_util/xsd/galaxy.xsd b/lib/galaxy/tool_util/xsd/galaxy.xsd
index 7fe009246720..cbdeaaa0997f 100644
--- a/lib/galaxy/tool_util/xsd/galaxy.xsd
+++ b/lib/galaxy/tool_util/xsd/galaxy.xsd
@@ -6143,6 +6143,78 @@ on Human (hg18)``.
 </outputs>
 ```
 
+### Markdown Outputs
+
+Tools can produce Markdown reports enhanced with the Galaxy Markdown syntax. This
+allows using Markdown directives to provide rich displays of tool inputs and outputs.
+
+```
+<outputs>
+    <data format="tool_markdown" name="output_report" label="Report for Analysis" />
+</outputs>
+```
+
+For an overview of standard Markdown visit the [commonmark.org tutorial](https://commonmark.org/help/tutorial/).
+
+The Galaxy extensions to Markdown are represented as code blocks, these blocks start with the line
+
+
+    ```galaxy
+
+and end with the line
+
+    ```
+
+and have a command (or directive) with arguments between these lines. These arguments reference parts of your tool's job such as
+inputs and outputs by label.
+
+#### History Contents Commands
+
+These commands reference a dataset or dataset collection. For instance, the following examples would display
+the dataset collection metadata and would embed a dataset into the document as an image.
+
+These elements are referenced by input or output labels for the tool.
+
+Example:
+
+    ```galaxy
+    history_dataset_collection_display(output=mapped_bams)
+    ```
+
+Example:
+
+    ```galaxy
+    history_dataset_as_image(output=normalized_result_plot)
+    ```
+
+$directive_list:history_dataset_display,history_dataset_collection_display,history_dataset_as_image,history_dataset_as_table,history_dataset_peek,history_dataset_info
+
+#### Job Commands
+
+These commands implicitly reference the Galaxy job associated with the tool execution.
+
+Example:
+
+    ```galaxy
+    tool_stdout()
+    ```
+
+$directive_list:tool_stderr,tool_stdout,job_metrics,job_parameters
+
+#### Example Tools
+
+A few potential paradigms for build reports for tools have examples included.
+[markdown_report_simple.xml](https://github.com/galaxyproject/galaxy/blob/dev/test/functional/tools/markdown_report_simple.xml)
+demonstrates simply linking to the other outputs of a tool and builds the document
+itself with a Galaxy ``configfile``. [markdown_report_extra_files.xml](https://github.com/galaxyproject/galaxy/blob/dev/test/functional/tools/markdown_report_extra_files.xml)
+builds the report with a configfile just like that first example but demonstrates
+copying data and images into the ``extra_files`` directory of the report. This variant
+is useful if the number or types of files being produced is variable or if it is important
+the outputs linked in the reports are not stand-alone outputs of the tool. Finally,
+[markdown_report_from_script.xml](https://github.com/galaxyproject/galaxy/blob/dev/test/functional/tools/markdown_report_from_script.xml)
+demonstrates you don't need to build the file in Galaxy's XML - you can build it with
+a wrapper script or standalone application.
+
 ]]></xs:documentation>
     </xs:annotation>
     <xs:sequence>
diff --git a/lib/galaxy/webapps/galaxy/api/datasets.py b/lib/galaxy/webapps/galaxy/api/datasets.py
index eba6795100fd..a16251734633 100644
--- a/lib/galaxy/webapps/galaxy/api/datasets.py
+++ b/lib/galaxy/webapps/galaxy/api/datasets.py
@@ -39,6 +39,7 @@
     AsyncTaskResultSummary,
     DatasetAssociationRoles,
     DatasetSourceType,
+    ToolReportForDataset,
 )
 from galaxy.util.zipstream import ZipstreamWrapper
 from galaxy.webapps.base.api import GalaxyFileResponse
@@ -189,9 +190,10 @@ def show_inheritance_chain(
     def get_content_as_text(
         self,
         dataset_id: HistoryDatasetIDPathParam,
+        filename: Optional[str] = FilenameQueryParam,
         trans=DependsOnTrans,
     ) -> DatasetTextContentDetails:
-        return self.service.get_content_as_text(trans, dataset_id)
+        return self.service.get_content_as_text(trans, dataset_id, filename=filename)
 
     @router.get(
         "/api/datasets/{dataset_id}/converted/{ext}",
@@ -503,6 +505,17 @@ def compute_hash(
     ) -> AsyncTaskResultSummary:
         return self.service.compute_hash(trans, dataset_id, payload, hda_ldda=hda_ldda)
 
+    @router.get(
+        "/api/datasets/{dataset_id}/report",
+        summary="Return JSON content Galaxy will use to render Markdown reports",
+    )
+    def report(
+        self,
+        dataset_id: HistoryDatasetIDPathParam,
+        trans=DependsOnTrans,
+    ) -> ToolReportForDataset:
+        return self.service.report(trans, dataset_id)
+
     @router.put(
         "/api/datasets/{dataset_id}/object_store_id",
         summary="Update an object store ID for a dataset you own.",
diff --git a/lib/galaxy/webapps/galaxy/buildapp.py b/lib/galaxy/webapps/galaxy/buildapp.py
index c3bb3a6810f4..b6de60509900 100644
--- a/lib/galaxy/webapps/galaxy/buildapp.py
+++ b/lib/galaxy/webapps/galaxy/buildapp.py
@@ -281,6 +281,7 @@ def app_pair(global_conf, load_app_kwds=None, wsgi_preflight=True, **kwargs):
     webapp.add_client_route("/datasets/{dataset_id}/error")
     webapp.add_client_route("/datasets/{dataset_id}/details")
     webapp.add_client_route("/datasets/{dataset_id}/preview")
+    webapp.add_client_route("/datasets/{dataset_id}/report")
     webapp.add_client_route("/datasets/{dataset_id}/show_params")
     webapp.add_client_route("/collection/{collection_id}/edit")
     webapp.add_client_route("/jobs/submission/success")
diff --git a/lib/galaxy/webapps/galaxy/services/datasets.py b/lib/galaxy/webapps/galaxy/services/datasets.py
index 32b0f8bd8c2c..e51eb3df1fd0 100644
--- a/lib/galaxy/webapps/galaxy/services/datasets.py
+++ b/lib/galaxy/webapps/galaxy/services/datasets.py
@@ -47,6 +47,10 @@
     HistoryContentsManager,
 )
 from galaxy.managers.lddas import LDDAManager
+from galaxy.managers.markdown_util import (
+    ready_galaxy_markdown_for_export,
+    resolve_job_markdown,
+)
 from galaxy.objectstore.badges import BadgeDict
 from galaxy.schema import (
     FilterQueryParams,
@@ -69,6 +73,7 @@
     DatasetSourceType,
     EncodedDatasetSourceId,
     Model,
+    ToolReportForDataset,
     UpdateDatasetPermissionsPayload,
 )
 from galaxy.schema.tasks import ComputeDatasetHashTaskRequest
@@ -510,6 +515,18 @@ def compute_hash(
         result = compute_dataset_hash.delay(request=request, task_user_id=getattr(trans.user, "id", None))
         return async_task_summary(result)
 
+    def report(self, trans: ProvidesHistoryContext, dataset_id: DecodedDatabaseIdField) -> ToolReportForDataset:
+        dataset_instance = self.hda_manager.get_accessible(dataset_id, trans.user)
+        self.hda_manager.ensure_dataset_on_disk(trans, dataset_instance)
+        file_path = trans.app.object_store.get_filename(dataset_instance.dataset)
+        raw_content = open(file_path).read(1024 * 10)
+        internal_markdown = resolve_job_markdown(trans, dataset_instance.creating_job, raw_content)
+        content, extra_attributes = ready_galaxy_markdown_for_export(trans, internal_markdown)
+        return ToolReportForDataset(
+            content=content,
+            **extra_attributes,
+        )
+
     def drs_dataset_instance(self, object_id: str) -> Tuple[int, DatasetSourceType]:
         if object_id.startswith("hda-"):
             decoded_object_id = self.decode_id(object_id[len("hda-") :], kind="drs")
@@ -660,15 +677,19 @@ def display(
         return rval, headers
 
     def get_content_as_text(
-        self,
-        trans: ProvidesHistoryContext,
-        dataset_id: DecodedDatabaseIdField,
+        self, trans: ProvidesHistoryContext, dataset_id: DecodedDatabaseIdField, filename: Optional[str]
     ) -> DatasetTextContentDetails:
         """Returns dataset content as Text."""
         user = trans.user
         hda = self.hda_manager.get_accessible(dataset_id, user)
         hda = self.hda_manager.error_if_uploading(hda)
-        truncated, dataset_data = self.hda_manager.text_data(hda, preview=True)
+        if filename and filename != "index":
+            object_store = trans.app.object_store
+            dir_name = hda.dataset.extra_files_path_name
+            file_path = object_store.get_filename(hda.dataset, extra_dir=dir_name, alt_name=filename)
+            truncated, dataset_data = self.hda_manager.text_data_truncated(file_path, preview=True)
+        else:
+            truncated, dataset_data = self.hda_manager.text_data(hda, preview=True)
         item_url = web.url_for(
             controller="dataset",
             action="display_by_username_and_slug",
diff --git a/test/functional/tools/data/1.bed b/test/functional/tools/data/1.bed
new file mode 100644
index 000000000000..eb4c30e347a1
--- /dev/null
+++ b/test/functional/tools/data/1.bed
@@ -0,0 +1,65 @@
+chr1	147962192	147962580	CCDS989.1_cds_0_0_chr1_147962193_r	0	-
+chr1	147984545	147984630	CCDS990.1_cds_0_0_chr1_147984546_f	0	+
+chr1	148078400	148078582	CCDS993.1_cds_0_0_chr1_148078401_r	0	-
+chr1	148185136	148185276	CCDS996.1_cds_0_0_chr1_148185137_f	0	+
+chr10	55251623	55253124	CCDS7248.1_cds_0_0_chr10_55251624_r	0	-
+chr11	116124407	116124501	CCDS8374.1_cds_0_0_chr11_116124408_r	0	-
+chr11	116206508	116206563	CCDS8377.1_cds_0_0_chr11_116206509_f	0	+
+chr11	116211733	116212337	CCDS8378.1_cds_0_0_chr11_116211734_r	0	-
+chr11	1812377	1812407	CCDS7726.1_cds_0_0_chr11_1812378_f	0	+
+chr12	38440094	38440321	CCDS8736.1_cds_0_0_chr12_38440095_r	0	-
+chr13	112381694	112381953	CCDS9526.1_cds_0_0_chr13_112381695_f	0	+
+chr14	98710240	98712285	CCDS9949.1_cds_0_0_chr14_98710241_r	0	-
+chr15	41486872	41487060	CCDS10096.1_cds_0_0_chr15_41486873_r	0	-
+chr15	41673708	41673857	CCDS10097.1_cds_0_0_chr15_41673709_f	0	+
+chr15	41679161	41679250	CCDS10098.1_cds_0_0_chr15_41679162_r	0	-
+chr15	41826029	41826196	CCDS10101.1_cds_0_0_chr15_41826030_f	0	+
+chr16	142908	143003	CCDS10397.1_cds_0_0_chr16_142909_f	0	+
+chr16	179963	180135	CCDS10401.1_cds_0_0_chr16_179964_r	0	-
+chr16	244413	244681	CCDS10402.1_cds_0_0_chr16_244414_f	0	+
+chr16	259268	259383	CCDS10403.1_cds_0_0_chr16_259269_r	0	-
+chr18	23786114	23786321	CCDS11891.1_cds_0_0_chr18_23786115_r	0	-
+chr18	59406881	59407046	CCDS11985.1_cds_0_0_chr18_59406882_f	0	+
+chr18	59455932	59456337	CCDS11986.1_cds_0_0_chr18_59455933_r	0	-
+chr18	59600586	59600754	CCDS11988.1_cds_0_0_chr18_59600587_f	0	+
+chr19	59068595	59069564	CCDS12866.1_cds_0_0_chr19_59068596_f	0	+
+chr19	59236026	59236146	CCDS12872.1_cds_0_0_chr19_59236027_r	0	-
+chr19	59297998	59298008	CCDS12877.1_cds_0_0_chr19_59297999_f	0	+
+chr19	59302168	59302288	CCDS12878.1_cds_0_0_chr19_59302169_r	0	-
+chr2	118288583	118288668	CCDS2120.1_cds_0_0_chr2_118288584_f	0	+
+chr2	118394148	118394202	CCDS2121.1_cds_0_0_chr2_118394149_r	0	-
+chr2	220190202	220190242	CCDS2441.1_cds_0_0_chr2_220190203_f	0	+
+chr2	220229609	220230869	CCDS2443.1_cds_0_0_chr2_220229610_r	0	-
+chr20	33330413	33330423	CCDS13249.1_cds_0_0_chr20_33330414_r	0	-
+chr20	33513606	33513792	CCDS13255.1_cds_0_0_chr20_33513607_f	0	+
+chr20	33579500	33579527	CCDS13256.1_cds_0_0_chr20_33579501_r	0	-
+chr20	33593260	33593348	CCDS13257.1_cds_0_0_chr20_33593261_f	0	+
+chr21	32707032	32707192	CCDS13614.1_cds_0_0_chr21_32707033_f	0	+
+chr21	32869641	32870022	CCDS13615.1_cds_0_0_chr21_32869642_r	0	-
+chr21	33321040	33322012	CCDS13620.1_cds_0_0_chr21_33321041_f	0	+
+chr21	33744994	33745040	CCDS13625.1_cds_0_0_chr21_33744995_r	0	-
+chr22	30120223	30120265	CCDS13897.1_cds_0_0_chr22_30120224_f	0	+
+chr22	30160419	30160661	CCDS13898.1_cds_0_0_chr22_30160420_r	0	-
+chr22	30665273	30665360	CCDS13901.1_cds_0_0_chr22_30665274_f	0	+
+chr22	30939054	30939266	CCDS13903.1_cds_0_0_chr22_30939055_r	0	-
+chr5	131424298	131424460	CCDS4149.1_cds_0_0_chr5_131424299_f	0	+
+chr5	131556601	131556672	CCDS4151.1_cds_0_0_chr5_131556602_r	0	-
+chr5	131621326	131621419	CCDS4152.1_cds_0_0_chr5_131621327_f	0	+
+chr5	131847541	131847666	CCDS4155.1_cds_0_0_chr5_131847542_r	0	-
+chr6	108299600	108299744	CCDS5061.1_cds_0_0_chr6_108299601_r	0	-
+chr6	108594662	108594687	CCDS5063.1_cds_0_0_chr6_108594663_f	0	+
+chr6	108640045	108640151	CCDS5064.1_cds_0_0_chr6_108640046_r	0	-
+chr6	108722976	108723115	CCDS5067.1_cds_0_0_chr6_108722977_f	0	+
+chr7	113660517	113660685	CCDS5760.1_cds_0_0_chr7_113660518_f	0	+
+chr7	116512159	116512389	CCDS5771.1_cds_0_0_chr7_116512160_r	0	-
+chr7	116714099	116714152	CCDS5773.1_cds_0_0_chr7_116714100_f	0	+
+chr7	116945541	116945787	CCDS5774.1_cds_0_0_chr7_116945542_r	0	-
+chr8	118881131	118881317	CCDS6324.1_cds_0_0_chr8_118881132_r	0	-
+chr9	128764156	128764189	CCDS6914.1_cds_0_0_chr9_128764157_f	0	+
+chr9	128787519	128789136	CCDS6915.1_cds_0_0_chr9_128787520_r	0	-
+chr9	128882427	128882523	CCDS6917.1_cds_0_0_chr9_128882428_f	0	+
+chr9	128937229	128937445	CCDS6919.1_cds_0_0_chr9_128937230_r	0	-
+chrX	122745047	122745924	CCDS14606.1_cds_0_0_chrX_122745048_f	0	+
+chrX	152648964	152649196	CCDS14733.1_cds_0_0_chrX_152648965_r	0	-
+chrX	152691446	152691471	CCDS14735.1_cds_0_0_chrX_152691447_f	0	+
+chrX	152694029	152694263	CCDS14736.1_cds_0_0_chrX_152694030_r	0	-
diff --git a/test/functional/tools/data/rgWebLogo3_test.jpg b/test/functional/tools/data/rgWebLogo3_test.jpg
new file mode 100644
index 000000000000..8f7e77eba67c
Binary files /dev/null and b/test/functional/tools/data/rgWebLogo3_test.jpg differ
diff --git a/test/functional/tools/markdown_report_extra_files.xml b/test/functional/tools/markdown_report_extra_files.xml
new file mode 100644
index 000000000000..acd49ebc37a7
--- /dev/null
+++ b/test/functional/tools/markdown_report_extra_files.xml
@@ -0,0 +1,53 @@
+<tool id="markdown_report_extra_files" name="markdown_report_extra_files" version="1.0">
+    <command><![CDATA[
+        mkdir '$output_report.extra_files_path';
+        cp '$__tool_directory__/data/1.bed' '$output_report.extra_files_path/test.bed';
+        cp '$__tool_directory__/data/rgWebLogo3_test.jpg' '$output_report.extra_files_path/rgWebLogo3_test.jpg';
+        echo "I am writing this to standard output!";
+        cp '${tool_markdown}' '${output_report}';
+    ]]></command>
+    <configfiles>
+        <configfile name="tool_markdown"><![CDATA[
+# ${title}
+
+Here is an image we just stuck in an extra files path
+
+```galaxy
+history_dataset_as_image(output=output_report, path="rgWebLogo3_test.jpg")
+```
+
+This is a fancy table using fancy table features for an extra files.
+
+```galaxy
+history_dataset_as_table(output=output_report, path="test.bed", title="A Fancy Title!", footer="Here is a small legend.")
+```
+
+The standard out for this tool execution is:
+
+```galaxy
+tool_stdout()
+```
+
+This is my document and I have populated the title from a parameter.
+]]></configfile>
+    </configfiles>
+    <inputs>
+        <param name="title" type="text" label="Title"/>
+    </inputs>
+    <outputs>
+        <!-- <data name="output_directory" format="html"/> -->
+        <data name="output_report" format="tool_markdown"/>
+    </outputs>
+    <tests>
+        <test>
+            <param name="title" value="foobar" />
+            <output name="output_report" ftype="tool_markdown">
+                <assert_contents>
+                    <has_line line="# foobar" />
+                </assert_contents>
+            </output>
+        </test>
+    </tests>
+    <help>
+    </help>
+</tool>
diff --git a/test/functional/tools/markdown_report_from_script.xml b/test/functional/tools/markdown_report_from_script.xml
new file mode 100644
index 000000000000..12237780345a
--- /dev/null
+++ b/test/functional/tools/markdown_report_from_script.xml
@@ -0,0 +1,30 @@
+<tool id="markdown_report_from_script" name="markdown_report_from_script" version="1.0">
+    <command><![CDATA[
+        echo "Some contents for standard output";
+        echo "Hello World" > '$output_text';
+        cp '$__tool_directory__/data/1.bed' '$output_table';
+        cp '$__tool_directory__/data/rgWebLogo3_test.jpg' '$output_image';
+        python '$__tool_directory__/markdown_report_simple_script.py'
+    ]]></command>
+    <inputs>
+        <param name="title" type="text" label="Title"/>
+    </inputs>
+    <outputs>
+        <data name="output_text" format="txt"/>
+        <data name="output_image" format="jpg"/>
+        <data name="output_table" format="tsv"/>
+        <data name="output_report" format="tool_markdown" from_work_dir="output_report.md" />
+    </outputs>
+    <tests>
+        <test>
+            <param name="title" value="foobar" />
+            <output name="output_report" ftype="tool_markdown">
+                <assert_contents>
+                    <has_line line="# Dynamically Generated Report" />
+                </assert_contents>
+            </output>
+        </test>
+    </tests>
+    <help>
+    </help>
+</tool>
diff --git a/test/functional/tools/markdown_report_simple.xml b/test/functional/tools/markdown_report_simple.xml
new file mode 100644
index 000000000000..bf893234144e
--- /dev/null
+++ b/test/functional/tools/markdown_report_simple.xml
@@ -0,0 +1,75 @@
+<tool id="markdown_report_simple" name="markdown_report_simple" version="1.0">
+    <command><![CDATA[
+        echo "Some contents for standard output";
+        echo "Hello World" > '$output_text';
+        cp '$__tool_directory__/data/1.bed' '$output_table';
+        cp '$__tool_directory__/data/rgWebLogo3_test.jpg' '$output_image';
+        cp '${tool_markdown}' '${output_report}';
+    ]]></command>
+    <configfiles>
+        <configfile name="tool_markdown"><![CDATA[
+# ${title}
+
+Here is a peek of the exciting stuff we did:
+
+```galaxy
+history_dataset_peek(output=output_text)
+```
+
+The tool produced the following image image:
+
+```galaxy
+history_dataset_as_image(output=output_image)
+```
+
+We produced a table that looks like this:
+
+```galaxy
+history_dataset_as_table(output=output_table, header="Table Header", footer="A description of the table", compact=true)
+```
+
+The same table as embedded and using the full dataset display:
+
+(embed)
+
+```galaxy
+history_dataset_embedded(output=output_table)
+```
+
+(display)
+
+```galaxy
+history_dataset_display(output=output_table)
+```
+
+The standard output for this tool execution is:
+
+```galaxy
+tool_stdout()
+```
+
+This is my document and I have populated the title from a parameter.
+]]></configfile>
+    </configfiles>
+    <inputs>
+        <param name="title" type="text" label="Title"/>
+    </inputs>
+    <outputs>
+        <data name="output_text" format="txt"/>
+        <data name="output_image" format="jpg"/>
+        <data name="output_table" format="tsv"/>
+        <data name="output_report" format="tool_markdown"/>
+    </outputs>
+    <tests>
+        <test>
+            <param name="title" value="foobar" />
+            <output name="output_report" ftype="tool_markdown">
+                <assert_contents>
+                    <has_line line="# foobar" />
+                </assert_contents>
+            </output>
+        </test>
+    </tests>
+    <help>
+    </help>
+</tool>
diff --git a/test/functional/tools/markdown_report_simple_script.py b/test/functional/tools/markdown_report_simple_script.py
new file mode 100644
index 000000000000..fbcf9e6c9502
--- /dev/null
+++ b/test/functional/tools/markdown_report_simple_script.py
@@ -0,0 +1,46 @@
+DOCUMENT = """
+# Dynamically Generated Report
+
+Here is a peek of the exciting stuff we did:
+
+```galaxy
+history_dataset_peek(output=output_text)
+```
+
+The tool produced the following image image:
+
+```galaxy
+history_dataset_as_image(output=output_image)
+```
+
+We produced a table that looks like this:
+
+```galaxy
+history_dataset_as_table(output=output_table, header="Table Header", footer="A description of the table", compact=true)
+```
+
+The same table as embedded and using the full dataset display:
+
+(embed)
+
+```galaxy
+history_dataset_embedded(output=output_table)
+```
+
+(display)
+
+```galaxy
+history_dataset_display(output=output_table)
+```
+
+The standard output for this tool execution is:
+
+```galaxy
+tool_stdout()
+```
+
+This is my document and I have populated the title from a parameter.
+"""
+
+with open("output_report.md", "w") as f:
+    f.write(DOCUMENT)
diff --git a/test/functional/tools/sample_datatypes_conf.xml b/test/functional/tools/sample_datatypes_conf.xml
index 534d35122ec9..4645c7581fb9 100644
--- a/test/functional/tools/sample_datatypes_conf.xml
+++ b/test/functional/tools/sample_datatypes_conf.xml
@@ -49,6 +49,7 @@
     <datatype extension="vcf_bgzip" type="galaxy.datatypes.tabular:VcfGz" display_in_upload="true"/>
     <datatype extension="html" type="galaxy.datatypes.text:Html" mimetype="text/html"/>
     <datatype extension="expression.json" type="galaxy.datatypes.text:ExpressionJson" display_in_upload="true"/>
+    <datatype extension="tool_markdown" type="galaxy.datatypes.text:Text"/>
     <datatype extension="data_manager_json" type="galaxy.datatypes.text:DataManagerJson" mimetype="application/json" subclass="true" display_in_upload="false"/>
     <datatype extension="data" type="galaxy.datatypes.data:Data" mimetype="application/octet-stream" max_optional_metadata_filesize="1048576" />
     <datatype extension="binary" type="galaxy.datatypes.binary:Binary" mimetype="application/octet-stream" max_optional_metadata_filesize="1048576" />
diff --git a/test/functional/tools/sample_tool_conf.xml b/test/functional/tools/sample_tool_conf.xml
index 9e4fe18b3282..ee18141319b7 100644
--- a/test/functional/tools/sample_tool_conf.xml
+++ b/test/functional/tools/sample_tool_conf.xml
@@ -234,6 +234,9 @@
   <tool file="integer_default.xml" />
   <tool file="float_default.xml" />
   <tool file="all_output_types.xml" />
+  <tool file="markdown_report_simple.xml" />
+  <tool file="markdown_report_extra_files.xml" />
+  <tool file="markdown_report_from_script.xml" />
   <tool file="multiple_versions_v01.xml" />
   <tool file="multiple_versions_v01galaxy6.xml" />
   <tool file="multiple_versions_v02.xml" />
